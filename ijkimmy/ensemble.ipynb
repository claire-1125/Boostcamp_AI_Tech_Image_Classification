{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python inference.py --model PretrainedModels --model_param resnet false --output_filename output-ResNet50_kfold_Ep60_Weightv0_AGM-20220302-ijkimmmy.csv --label age gender mask --model_dir ./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER ./model/mask/ResNet50_Ep60_Weightv0_MASK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/bc-ai-recsys3-lv1-imgclassification\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import model.model as model_model\n",
    "from dataset import TestDataset, MaskBaseDataset\n",
    "from model.loss import create_criterion\n",
    "\n",
    "\n",
    "def load_model(model_name, saved_model, num_classes, model_param, device):\n",
    "    model_cls = getattr(model_model, model_name)\n",
    "    model = model_cls(\n",
    "        num_classes=num_classes,\n",
    "        **model_param\n",
    "    )\n",
    "    \n",
    "    model_path = os.path.join(saved_model, 'best.pth')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def parse_config(model_dirs):\n",
    "    # parse config files for model directory\n",
    "    import json\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    label_numclasses = {\n",
    "        'age': 3,\n",
    "        'gender': 2,\n",
    "        'mask': 3\n",
    "    }\n",
    "    \n",
    "    configs = dict((label, []) for label in label_numclasses.keys())\n",
    "    # for idx, model_dir in enumerate(model_dirs.split(sep=' ')):\n",
    "    for idx, model_dir in enumerate(model_dirs):\n",
    "        with open(os.path.join(model_dir, 'config.json'), 'r') as jsonfile:\n",
    "            config = json.load(jsonfile)\n",
    "            label = config['label']\n",
    "            config['num_classes'] = label_numclasses[label]\n",
    "            config['model_dir'] = model_dir\n",
    "            config['model_name'] = config['model']\n",
    "            del config['model']\n",
    "            configs[label].append(config)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def set_models(configs):\n",
    "    # takes as input a list of configurations with same labels, add model within config\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model_param_module = getattr(import_module(\"train\"), 'parse_model_param')\n",
    "    for config in configs:\n",
    "        pretrained = config['model_name'] in ['VGGFace', 'PretrainedModels']\n",
    "        model_param = model_param_module(config['model_param'], pretrained)\n",
    "        model = load_model(\n",
    "            config['model_name'],\n",
    "            config['model_dir'],\n",
    "            config['num_classes'],\n",
    "            model_param,\n",
    "            device\n",
    "        )\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        config['model'] = model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(data_dir, model_dirs, output_dir, args):\n",
    "    img_root = os.path.join(data_dir, 'images')\n",
    "    info_path = os.path.join(data_dir, 'info.csv')\n",
    "    info = pd.read_csv(info_path)\n",
    "\n",
    "    img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "    dataset = TestDataset(img_paths, args.resize)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    configs_label = parse_config(model_dirs)\n",
    "    for _, config in configs_label.items():\n",
    "        set_models(config)\n",
    "    \n",
    "    assert all([configs_label['age'], configs_label['gender'], configs_label['mask']]) # must have em all\n",
    "    age_soft, age_hard = inference_model(configs_label['age'], loader)\n",
    "    gen_soft, gen_hard = inference_model(configs_label['gender'], loader)\n",
    "    msk_soft, msk_hard = inference_model(configs_label['mask'], loader)\n",
    "    \n",
    "    pred_soft = msk_soft*6 + gen_soft * 3 + age_soft\n",
    "    pred_hard = msk_hard*6 + gen_hard * 3 + age_hard\n",
    "    \n",
    "    info['ans'] = pred_soft\n",
    "    info.to_csv(os.path.join(output_dir, 'soft', args.output_filename), index=False)\n",
    "    info['ans'] = pred_hard\n",
    "    info.to_csv(os.path.join(output_dir, 'hard', args.output_filename), index=False)\n",
    "    print(f'Inference Done!')\n",
    "\n",
    "\n",
    "def inference_model(configs, loader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    \n",
    "    lst_soft = []\n",
    "    df_hard = pd.DataFrame()\n",
    "    for config in configs:\n",
    "        model = config['model']\n",
    "        model_name = config['model_dir']\n",
    "        model.eval()\n",
    "        \n",
    "        preds_soft = []\n",
    "        preds_hard = []\n",
    "        print(f\"Calculating inference results for {model_name}..\")\n",
    "        with torch.no_grad():\n",
    "            for idx, images in enumerate(loader):\n",
    "                images = images.to(device)\n",
    "                pred = model(images)\n",
    "                pred_soft = pred.cpu().numpy()\n",
    "                preds_soft.extend(pred_soft)\n",
    "                pred_hard = pred.argmax(dim=-1).cpu().numpy()\n",
    "                preds_hard.extend(pred_hard)\n",
    "        lst_soft.append(preds_soft)\n",
    "        df_hard[model_name] = preds_hard\n",
    "    # return lst_soft, df_hard\n",
    "    np_soft = np.array(lst_soft)\n",
    "    np_soft = np_soft.sum(axis=0)/np_soft.shape[0]  # (sum the results of each model) / div # of models\n",
    "    np_soft = np_soft.argmax(axis=1)\n",
    "    np_hard = np.asarray(df_hard.mode(axis=1)[0])\n",
    "    return np_soft, np_hard\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # Data and model checkpoints directories\n",
    "#     parser.add_argument('--batch_size', type=int, default=500, help='input batch size for validing (default: 1000)')\n",
    "#     parser.add_argument('--resize', type=tuple, default=(224, 224), help='resize size for image when you trained (default: (96, 128))')\n",
    "#     parser.add_argument('--output_filename', type=str, default='output.csv')\n",
    "\n",
    "#     # Container environment\n",
    "#     parser.add_argument('--data_dir', type=str, default=os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/eval'))\n",
    "#     parser.add_argument('--model_dirs', nargs='+', default=os.environ.get('SM_CHANNEL_MODEL', './model'))\n",
    "#     parser.add_argument('--output_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR', './output'))\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     data_dir = args.data_dir\n",
    "#     model_dirs = args.model_dirs\n",
    "#     output_dir = args.output_dir\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     inference(data_dir, model_dirs, output_dir, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/eval'\n",
    "resize = (224, 224)\n",
    "batch_size = 200\n",
    "\n",
    "img_root = os.path.join(data_dir, 'images')\n",
    "info_path = os.path.join(data_dir, 'info.csv')\n",
    "info = pd.read_csv(info_path)\n",
    "\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "dataset = TestDataset(img_paths, resize)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inference results for ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE..\n",
      "Calculating inference results for ./model/age/ResNet50_Ep60_Weightv0_AGE..\n",
      "Calculating inference results for ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER..\n",
      "Calculating inference results for ./model/gender/ResNet50_Ep60_Weightv0_GENDER2..\n",
      "Calculating inference results for ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK..\n",
      "Calculating inference results for ./model/mask/ResNet50_Ep60_Weightv0_MASK2..\n"
     ]
    }
   ],
   "source": [
    "model_dirs = \"./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\n",
    "./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2\" # \\\n",
    "# ./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\n",
    "# ./model/age/ResNet18_Ep60_Weightv3_AGE ./model/gender/ResNet18_Ep60_Weightv3_GENDER ./model/mask/ResNet18_Ep60_Weightv3_MASK ./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2 ./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK\"\n",
    "model_dirs = model_dirs.split(sep=' ')\n",
    "\n",
    "configs_label = parse_config(model_dirs)\n",
    "for _, config in configs_label.items():\n",
    "    set_models(config)\n",
    "    \n",
    "assert all([configs_label['age'], configs_label['gender'], configs_label['mask']]) # must have em all\n",
    "age_soft, age_hard = inference_model(configs_label['age'], loader)\n",
    "gen_soft, gen_hard = inference_model(configs_label['gender'], loader)\n",
    "msk_soft, msk_hard = inference_model(configs_label['mask'], loader)\n",
    "    \n",
    "pred_soft = msk_soft*6 + gen_soft * 3 + age_soft\n",
    "pred_hard = msk_hard*6 + gen_hard * 3 + age_hard\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done!\n"
     ]
    }
   ],
   "source": [
    "output_dir = './output'\n",
    "output_filename = 'ensemble_try0.csv'\n",
    "\n",
    "info['ans'] = pred_soft\n",
    "info.to_csv(os.path.join(output_dir, 'output_soft_' + output_filename), index=False)\n",
    "info['ans'] = pred_hard\n",
    "info.to_csv(os.path.join(output_dir, 'output_hard_' + output_filename), index=False)\n",
    "print(f'Inference Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
