{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD\n",
    "        \n",
    "_file_names = {\n",
    "    \"mask1\": MaskLabels.MASK,\n",
    "    \"mask2\": MaskLabels.MASK,\n",
    "    \"mask3\": MaskLabels.MASK,\n",
    "    \"mask4\": MaskLabels.MASK,\n",
    "    \"mask5\": MaskLabels.MASK,\n",
    "    \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "    \"normal\": MaskLabels.NORMAL\n",
    "}\n",
    "\n",
    "def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "    return mask_label * 6 + gender_label * 3 + age_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train/images'\n",
    "downsample = True\n",
    "n_fold = 5\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "mask_labels = []\n",
    "gender_labels = []\n",
    "age_labels = []\n",
    "multi_labels = []\n",
    "\n",
    "indices = {}\n",
    "folds = []\n",
    "\n",
    "def k_stratified_fold(profiles):\n",
    "# profiles = [profile for profile in os.listdir(data_dir) if not profile.startswith('.')]\n",
    "    profile_labels = []\n",
    "    for profile in profiles:\n",
    "        id, gender, _, age = profile.split('_')\n",
    "        gender_label = GenderLabels.from_str(gender)\n",
    "        age_label = AgeLabels.from_number(age)\n",
    "        profile_label = encode_multi_class(0, gender_label, age_label)\n",
    "        profile_labels.append(profile_label)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_fold)\n",
    "    kfold_profiles = []\n",
    "    for train_index, val_index in skf.split(profiles, profile_labels):\n",
    "        kfold_profiles.append({\n",
    "            'train': train_index,\n",
    "            'val': val_index\n",
    "        })\n",
    "    return kfold_profiles\n",
    "\n",
    "\n",
    "def setup():\n",
    "    profiles = [profile for profile in os.listdir(data_dir) if not profile.startswith('.')]\n",
    "    kfold_profiles = k_stratified_fold(profiles)\n",
    "    for kfold_profile in kfold_profiles:\n",
    "        for phase, indices in kfold_profile:\n",
    "            for _idx in indices:\n",
    "                include_mask = True\n",
    "                profile = profiles[_idx]\n",
    "                img_folder = os.path.join(data_dir, profile)\n",
    "                lst_dir = os.listdir(img_folder)\n",
    "                random.shuffle(lst_dir)  # in-place operation (add randomness in selected images with mask label)\n",
    "                for file_name in lst_dir:\n",
    "                    _file_name, ext = os.path.splitext(file_name)\n",
    "                    if _file_name not in _file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                        continue\n",
    "                    if ext != '.jpg':\n",
    "                        continue\n",
    "                    if downsample and file_name.startswith('mask'):\n",
    "                        if not include_mask:\n",
    "                            continue\n",
    "                        include_mask = False # include only 1 mask image per profile\n",
    "\n",
    "                    img_path = os.path.join(data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                    mask_label = _file_names[_file_name]\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = GenderLabels.from_str(gender)\n",
    "                    age_label = AgeLabels.from_number(age)\n",
    "                    image_paths.append(img_path)\n",
    "                    mask_labels.append(mask_label)\n",
    "                    gender_labels.append(gender_label)\n",
    "                    age_labels.append(age_label)\n",
    "                    multi_labels.append(self.encode_multi_class(mask_label, gender_label, age_label))\n",
    "                    indices[phase].append(cnt)\n",
    "                    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, Subset, random_split, WeightedRandomSampler\n",
    "# from torchvision import transforms\n",
    "# from torchvision.transforms import *\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class MaskBaseDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    profiles = []\n",
    "    \n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "    multi_labels = []  \n",
    "    \n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.downsample = True\n",
    "        \n",
    "        self.setup()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.read_image(index), self.multi_labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(image_paths)\n",
    "    \n",
    "    def setup(self):\n",
    "        self.profiles = [profile for profile in os.listdir(self.data_dir) if not profile.startswith('.')]\n",
    "        for profile in self.profiles:\n",
    "            _, gender, _, age = profile.split(\"_\")\n",
    "            gender_label = GenderLabels.from_str(gender)\n",
    "            age_label = AgeLabels.from_number(age)\n",
    "            \n",
    "            include_mask = True\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            lst_files = os.listdir(img_folder)\n",
    "            random.shuffle(lst_files) # in-place operation (add randomness in selected images with mask label)\n",
    "            for file_name in lst_files:\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "                # if ext != '.jpg': # contains some png files\n",
    "                #     continue\n",
    "                if self.downsample and file_name.startswith('mask'):\n",
    "                    if not include_mask:\n",
    "                        continue\n",
    "                    include_mask = False # include only 1 mask image per profile\n",
    "                \n",
    "                img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                self.multi_labels.append(self.encode_multi_class(mask_label, gender_label, age_label))\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp\n",
    "\n",
    "    def read_image(self, index):\n",
    "        # read an image from directory and return it as a numpy array\n",
    "        image_path = self.image_paths[index]\n",
    "        return np.array(Image.open(image_path))\n",
    "\n",
    "\n",
    "class MaskSplitByProfileDataset(MaskBaseDataset):\n",
    "    # calc_statistics self.image_paths[:3000]:\n",
    "    #   [0.5573112  0.52429302 0.50174594] [0.61373778 0.58633636 0.56743769]\n",
    "    def __init__(self, data_dir, label='multi', n_fold:int=2, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        super().__init__(data_dir, mean, std)\n",
    "        \n",
    "        self.label = label\n",
    "        self.set_target_label()\n",
    "        \n",
    "        self.n_fold = n_fold\n",
    "        self.kfold_indices = []\n",
    "        self.stratified_kfold()\n",
    "        self.indices = self.kfold_indices[0]\n",
    "        \n",
    "        self.class_weights = self.compute_class_weight()\n",
    "        \n",
    "    def set_target_label(self):\n",
    "        if self.label == 'multi':\n",
    "            self.num_classes = 3 * 2 * 3\n",
    "            self.target_label = self.multi_labels\n",
    "        elif self.label == 'mask':\n",
    "            self.num_classes = 3\n",
    "            self.target_label = self.mask_labels\n",
    "        elif self.label == 'gender':\n",
    "            self.num_classes = 2\n",
    "            self.target_label = self.gender_labels\n",
    "        elif self.label == 'age':\n",
    "            self.num_classes = 3\n",
    "            self.target_label = self.age_labels\n",
    "        else:\n",
    "            raise ValueError(f\"label must be 'multi', 'mask', 'gender', or 'age', {self.label}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.read_image(index), self.target_label[index]\n",
    "\n",
    "    def stratified_kfold(self):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        \n",
    "        profile_labels = []\n",
    "        for profile in self.profiles:\n",
    "            _, gender, _, age = profile.split(\"_\")\n",
    "            gender_label = GenderLabels.from_str(gender)\n",
    "            age_label = AgeLabels.from_number(age)\n",
    "            profile_label = self.encode_multi_class(0, gender_label, age_label)\n",
    "            profile_labels.append(profile_label)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.n_fold)\n",
    "        for train_profiles, val_profiles in skf.split(self.profiles, profile_labels):\n",
    "            train_index, val_index = [], []\n",
    "            for profile_idx in train_profiles:\n",
    "                train_index.extend(range(profile_idx*3, profile_idx*3+3))\n",
    "            for profile_idx in val_profiles:\n",
    "                val_index.extend(range(profile_idx*3, profile_idx*3+3))\n",
    "            self.kfold_indices.append({\n",
    "                'train': train_index,\n",
    "                'val': val_index\n",
    "            })\n",
    "\n",
    "    def split_dataset(self) -> List[Subset]:\n",
    "        return [Subset(self, indices) for phase, indices in self.indices.items()]\n",
    "    \n",
    "    def get_train_labels(self, label):\n",
    "        # returns train data of the input label\n",
    "        train_index = self.indices['train']\n",
    "        return [label[idx] for idx in train_index]\n",
    "    \n",
    "    def get_classweight_label(self, label) -> torch.tensor:\n",
    "        # returns class weight of a label within train dataset\n",
    "        train_labels = self.get_train_labels(label)\n",
    "        _, n_samples = np.unique(train_labels, return_counts=True)\n",
    "        weights = 1. / torch.tensor(n_samples, dtype=torch.float)\n",
    "        return weights\n",
    "    \n",
    "    def normalize_weight(self, weights):\n",
    "        norm_weights = [1 - (weight / sum(weights)) for weight in weights]\n",
    "        return torch.tensor(norm_weights, dtype=torch.float)\n",
    "\n",
    "    ##################### need refactoring ##################### \n",
    "    def weight0(self):\n",
    "        # v0: weights on target label\n",
    "        train_index = self.indices['train'] # indices of train dataset\n",
    "        train_labels = [self.target_label[idx] for idx in train_index] # target_label of train dataset\n",
    "        class_counts = np.array([len(np.where(train_labels==t)[0]) for t in np.unique(train_labels)]) # get counts of each class \n",
    "        weights = 1. / torch.tensor(class_counts, dtype=torch.float) # get weights (more class count == less weight(frequent) it will be sampled)\n",
    "        samples_weights = weights[train_labels] # map weights for each train dataset, len(samples_weights) == len(train dataset)\n",
    "        return WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
    "    \n",
    "    def weight1(self):\n",
    "        # v1: normalized weights on target label (better than v0)\n",
    "        sample_weight = [self.class_weights[self.target_label[idx]] for idx in self.indices['train']]\n",
    "        return WeightedRandomSampler(weights=sample_weight, num_samples=len(sample_weight), replacement=True)\n",
    "\n",
    "    def weight2(self):\n",
    "        # # v2: normalized weights on of specific ratio ``age=.9 : gender=.1``\n",
    "        age_weight = self.get_classweight_label(self.age_labels)\n",
    "        gender_weight = self.get_classweight_label(self.gender_labels)\n",
    "        weights = [age_weight[self.age_labels[idx]]*.9 + gender_weight[self.gender_labels[idx]]*.1 for idx in self.indices['train']]\n",
    "        return WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    def weight3(self):\n",
    "        # v3: normalized weights on multi label\n",
    "        multi_weight = self.get_classweight_label(self.multi_labels)\n",
    "        multi_weight = self.normalize_weight(multi_weight)\n",
    "        sample_weight = [multi_weight[self.multi_labels[idx]] for idx in self.indices['train']]\n",
    "        return WeightedRandomSampler(weights=sample_weight, num_samples=len(sample_weight), replacement=True)\n",
    "\n",
    "    def weight4(self):\n",
    "        # v4: weights on multi label\n",
    "        multi_weight = self.get_classweight_label(self.multi_labels)\n",
    "        sample_weight = [multi_weight[self.multi_labels[idx]] for idx in self.indices['train']]\n",
    "        return WeightedRandomSampler(weights=sample_weight, num_samples=len(sample_weight), replacement=True)\n",
    "\n",
    "    def get_weighted_sampler(self, ver: int=0) -> WeightedRandomSampler:  \n",
    "        \"\"\"\n",
    "        returns WeightedRandomSampler based on the distribution of the train label\n",
    "        used to prevent overfitting due to unbalanced dataset\n",
    "        \"\"\"\n",
    "        if ver==0: return self.weight0()\n",
    "        elif ver==1: return self.weight1()\n",
    "        elif ver==2: return self.weight2()\n",
    "        elif ver==3: return self.weight3()\n",
    "        elif ver==4: return self.weight4()\n",
    "        else: raise ValueError(f'invalid version of {ver}')\n",
    "\n",
    "    def compute_class_weight(self) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        estimate class weights for unbalanced dataset\n",
    "        `` 1 - n_sample / sum(n_samples) ````\n",
    "        used for loss function: weighted_cross_entropy\n",
    "        \"\"\"\n",
    "        train_index = self.indices['train']\n",
    "        train_labels = [self.target_label[idx] for idx in train_index]\n",
    "        _, n_samples = np.unique(train_labels, return_counts=True)\n",
    "        norm_weights = [1 - (sample / sum(n_samples)) for sample in n_samples]\n",
    "        return torch.tensor(norm_weights, dtype=torch.float).to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6480\n",
      "8100\n",
      "image_paths   = 8100\n",
      "profiles      = 2700\n",
      "mask_labels   = 8100\n",
      "gender_labels = 8100\n",
      "age_labels    = 8100\n",
      "multi_labels  = 8100\n"
     ]
    }
   ],
   "source": [
    "label = 'age'\n",
    "k_folds = 5\n",
    "\n",
    "dataset = MaskSplitByProfileDataset(\n",
    "    data_dir=data_dir,\n",
    "    label=label,\n",
    "    n_fold=k_folds\n",
    ")\n",
    "num_classes = dataset.num_classes  # 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<AgeLabels.YOUNG: 0>, <AgeLabels.MIDDLE: 1>, <AgeLabels.OLD: 2>}\n"
     ]
    }
   ],
   "source": [
    "print(set(dataset.target_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "{<MaskLabels.MASK: 0>, <MaskLabels.INCORRECT: 1>, <MaskLabels.NORMAL: 2>}\n",
      "{<GenderLabels.MALE: 0>, <GenderLabels.FEMALE: 1>}\n",
      "{<AgeLabels.YOUNG: 0>, <AgeLabels.MIDDLE: 1>, <AgeLabels.OLD: 2>}\n"
     ]
    }
   ],
   "source": [
    "print(set(dataset.multi_labels))\n",
    "print(set(dataset.mask_labels))\n",
    "print(set(dataset.gender_labels))\n",
    "print(set(dataset.age_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: train=6480, test=1620, total=8100\n",
      "train set count=6480, val set count=1620\n",
      "1: train=6480, test=1620, total=8100\n",
      "train set count=6480, val set count=1620\n",
      "2: train=6480, test=1620, total=8100\n",
      "train set count=6480, val set count=1620\n",
      "3: train=6480, test=1620, total=8100\n",
      "train set count=6480, val set count=1620\n",
      "4: train=6480, test=1620, total=8100\n",
      "train set count=6480, val set count=1620\n"
     ]
    }
   ],
   "source": [
    "for idx, indices in enumerate(dataset.kfold_indices):\n",
    "    print(f'{idx}: train={len(indices[\"train\"])}, test={len(indices[\"val\"])}, total={len(indices[\"train\"])+len(indices[\"val\"])}')\n",
    "    print(f'train set count={len(set(indices[\"train\"]))}, val set count={len(set(indices[\"val\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_profiles = {\n",
    "    'train': [dataset.image_paths[idx].split(sep='/')[7] for idx in dataset.kfold_indices[0]['train']],\n",
    "    'val': [dataset.image_paths[idx].split(sep='/')[7] for idx in dataset.kfold_indices[0]['val']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30932"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6480"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fold0_profiles['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001596_male_Asian_26'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = dataset.kfold_indices[0]['train'][0]\n",
    "dataset.image_paths[idx].split(sep='/')[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_0 = dataset.kfold_indices[0]['train']\n",
    "set_train_0 = set([dataset.image_paths[idx].split(sep='/')[7] for idx in trainset_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset_0 = dataset.kfold_indices[0]['val']\n",
    "set_val_0 = set([dataset.image_paths[idx].split(sep='/')[7] for idx in valset_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "lst_cheating = []\n",
    "for train_profile in set_train_0:\n",
    "    if train_profile in set_val_0:\n",
    "        lst_cheating.append(train_profile)\n",
    "print(len(lst_cheating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing\n",
    "\n",
    "# -- augmentation\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "        \n",
    "# -- data_loader\n",
    "sampler = dataset.get_weighted_sampler(0) # WeightedRandomSampler\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    num_workers=multiprocessing.cpu_count()//2,\n",
    "    # shuffle=True,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True,\n",
    "    sampler=sampler,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[203, 172, 128],\n",
      "          [206, 175, 131],\n",
      "          [208, 177, 133],\n",
      "          ...,\n",
      "          [144, 135, 154],\n",
      "          [144, 135, 154],\n",
      "          [144, 135, 154]],\n",
      "\n",
      "         [[203, 172, 128],\n",
      "          [206, 175, 131],\n",
      "          [208, 177, 133],\n",
      "          ...,\n",
      "          [143, 134, 153],\n",
      "          [144, 135, 154],\n",
      "          [144, 135, 154]],\n",
      "\n",
      "         [[204, 173, 129],\n",
      "          [206, 175, 131],\n",
      "          [208, 177, 133],\n",
      "          ...,\n",
      "          [143, 134, 153],\n",
      "          [143, 134, 153],\n",
      "          [144, 135, 154]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[157, 123,  96],\n",
      "          [152, 123,  93],\n",
      "          [148, 127,  96],\n",
      "          ...,\n",
      "          [  4,  25, 106],\n",
      "          [  4,  25, 106],\n",
      "          [  5,  26, 107]],\n",
      "\n",
      "         [[154, 123,  92],\n",
      "          [144, 118,  85],\n",
      "          [142, 123,  91],\n",
      "          ...,\n",
      "          [  4,  25, 106],\n",
      "          [  4,  25, 106],\n",
      "          [  5,  26, 107]],\n",
      "\n",
      "         [[152, 122,  88],\n",
      "          [139, 113,  78],\n",
      "          [137, 118,  86],\n",
      "          ...,\n",
      "          [  4,  25, 106],\n",
      "          [  4,  25, 106],\n",
      "          [  5,  26, 107]]],\n",
      "\n",
      "\n",
      "        [[[187, 183, 182],\n",
      "          [187, 183, 182],\n",
      "          [187, 183, 182],\n",
      "          ...,\n",
      "          [ 97,  88,  83],\n",
      "          [ 97,  88,  83],\n",
      "          [ 96,  87,  82]],\n",
      "\n",
      "         [[187, 183, 182],\n",
      "          [187, 183, 182],\n",
      "          [188, 184, 183],\n",
      "          ...,\n",
      "          [ 97,  88,  83],\n",
      "          [ 97,  88,  83],\n",
      "          [ 96,  87,  82]],\n",
      "\n",
      "         [[187, 183, 182],\n",
      "          [188, 184, 183],\n",
      "          [188, 184, 183],\n",
      "          ...,\n",
      "          [ 97,  88,  83],\n",
      "          [ 96,  87,  82],\n",
      "          [ 96,  87,  82]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 95,  94,  90],\n",
      "          [ 96,  95,  91],\n",
      "          [ 89,  88,  84],\n",
      "          ...,\n",
      "          [113, 114, 109],\n",
      "          [113, 114, 109],\n",
      "          [112, 113, 108]],\n",
      "\n",
      "         [[ 95,  94,  90],\n",
      "          [ 96,  95,  91],\n",
      "          [ 89,  88,  84],\n",
      "          ...,\n",
      "          [111, 112, 107],\n",
      "          [111, 112, 107],\n",
      "          [110, 111, 106]],\n",
      "\n",
      "         [[ 96,  95,  91],\n",
      "          [ 96,  95,  91],\n",
      "          [ 89,  88,  84],\n",
      "          ...,\n",
      "          [110, 111, 106],\n",
      "          [109, 110, 105],\n",
      "          [109, 110, 105]]],\n",
      "\n",
      "\n",
      "        [[[197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          ...,\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70]],\n",
      "\n",
      "         [[197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          ...,\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70]],\n",
      "\n",
      "         [[197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          [197, 197, 197],\n",
      "          ...,\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70],\n",
      "          [ 75,  74,  70]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[126, 117,  88],\n",
      "          [164, 155, 126],\n",
      "          [192, 185, 156],\n",
      "          ...,\n",
      "          [107, 118, 102],\n",
      "          [ 97, 110,  93],\n",
      "          [ 72,  85,  68]],\n",
      "\n",
      "         [[120, 111,  80],\n",
      "          [135, 126,  95],\n",
      "          [148, 141, 112],\n",
      "          ...,\n",
      "          [104, 115,  99],\n",
      "          [ 98, 111,  94],\n",
      "          [ 76,  89,  72]],\n",
      "\n",
      "         [[117, 108,  75],\n",
      "          [108,  99,  68],\n",
      "          [107, 101,  69],\n",
      "          ...,\n",
      "          [107, 118, 102],\n",
      "          [103, 116,  99],\n",
      "          [ 82,  95,  78]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          ...,\n",
      "          [168, 177, 172],\n",
      "          [158, 168, 160],\n",
      "          [155, 165, 156]],\n",
      "\n",
      "         [[183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          ...,\n",
      "          [168, 177, 172],\n",
      "          [158, 168, 160],\n",
      "          [155, 165, 156]],\n",
      "\n",
      "         [[183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          [183, 195, 195],\n",
      "          ...,\n",
      "          [168, 177, 172],\n",
      "          [158, 168, 160],\n",
      "          [156, 166, 157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[174,  48,  23],\n",
      "          [172,  46,  21],\n",
      "          [172,  47,  19],\n",
      "          ...,\n",
      "          [159,  34,  14],\n",
      "          [158,  33,  15],\n",
      "          [158,  33,  15]],\n",
      "\n",
      "         [[174,  48,  23],\n",
      "          [172,  46,  21],\n",
      "          [172,  47,  19],\n",
      "          ...,\n",
      "          [159,  34,  14],\n",
      "          [158,  33,  15],\n",
      "          [158,  33,  15]],\n",
      "\n",
      "         [[174,  48,  23],\n",
      "          [172,  46,  21],\n",
      "          [172,  47,  19],\n",
      "          ...,\n",
      "          [159,  34,  14],\n",
      "          [158,  33,  15],\n",
      "          [158,  33,  15]]],\n",
      "\n",
      "\n",
      "        [[[229,  54,  67],\n",
      "          [221,  57,  68],\n",
      "          [216,  56,  68],\n",
      "          ...,\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229]],\n",
      "\n",
      "         [[228,  53,  66],\n",
      "          [220,  56,  67],\n",
      "          [216,  56,  68],\n",
      "          ...,\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229]],\n",
      "\n",
      "         [[227,  52,  65],\n",
      "          [220,  56,  67],\n",
      "          [217,  57,  69],\n",
      "          ...,\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229],\n",
      "          [226, 230, 229]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[229, 229, 229],\n",
      "          [229, 229, 229],\n",
      "          [228, 228, 228],\n",
      "          ...,\n",
      "          [193, 198, 201],\n",
      "          [193, 198, 201],\n",
      "          [194, 199, 202]],\n",
      "\n",
      "         [[229, 229, 229],\n",
      "          [229, 229, 229],\n",
      "          [228, 228, 228],\n",
      "          ...,\n",
      "          [193, 198, 201],\n",
      "          [193, 198, 201],\n",
      "          [194, 199, 202]],\n",
      "\n",
      "         [[229, 229, 229],\n",
      "          [229, 229, 229],\n",
      "          [228, 228, 228],\n",
      "          ...,\n",
      "          [192, 197, 200],\n",
      "          [193, 198, 201],\n",
      "          [193, 198, 201]]],\n",
      "\n",
      "\n",
      "        [[[106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          ...,\n",
      "          [119, 151, 136],\n",
      "          [120, 152, 137],\n",
      "          [120, 152, 137]],\n",
      "\n",
      "         [[106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          ...,\n",
      "          [119, 151, 136],\n",
      "          [120, 152, 137],\n",
      "          [120, 152, 137]],\n",
      "\n",
      "         [[106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          [106, 140, 124],\n",
      "          ...,\n",
      "          [119, 151, 136],\n",
      "          [119, 151, 136],\n",
      "          [120, 152, 137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 38,  66,  52],\n",
      "          [ 34,  68,  51],\n",
      "          [ 33,  68,  48],\n",
      "          ...,\n",
      "          [104,   6,   0],\n",
      "          [117,  10,   2],\n",
      "          [126,  13,   5]],\n",
      "\n",
      "         [[ 39,  67,  53],\n",
      "          [ 34,  68,  51],\n",
      "          [ 33,  68,  48],\n",
      "          ...,\n",
      "          [104,   6,   0],\n",
      "          [116,   9,   0],\n",
      "          [126,  13,   5]],\n",
      "\n",
      "         [[ 39,  67,  53],\n",
      "          [ 34,  68,  51],\n",
      "          [ 33,  68,  48],\n",
      "          ...,\n",
      "          [106,   8,   0],\n",
      "          [118,  11,   1],\n",
      "          [128,  15,   7]]]], dtype=torch.uint8)\n",
      "tensor([16, 11, 15,  2, 11, 12,  3,  6,  0, 12, 11, 11, 15,  1, 13,  0])\n"
     ]
    }
   ],
   "source": [
    "for idx, train_batch in enumerate(train_loader):\n",
    "    inputs, labels = train_batch\n",
    "    print(inputs)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=args.valid_batch_size,\n",
    "    num_workers=multiprocessing.cpu_count()//2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
